import google.generativeai as genai

def ask_gemini(user_input):
    """
    This function sends a prompt to the Gemini model and returns the response.

    Args:
        user_input: The user's question or prompt as a string.

    Returns:
        The response generated by the Gemini model as a string.
    """

    # Import the library
    

    # Configure with your API key (replace with actual key)
    genai.configure(api_key="AIzaSyDqv8P18NqfqM3kDEQR4kbBNk_KVvL-lHM")

    # Set up the model configuration
    generation_config = {
        "temperature": 0.9,
        "top_p": 1,
        "top_k": 1,
        "max_output_tokens": 2048,
    }

    safety_settings = [
        {
        "category": "HARM_CATEGORY_HARASSMENT",
        "threshold": "BLOCK_MEDIUM_AND_ABOVE"
        },
        {
        "category": "HARM_CATEGORY_HATE_SPEECH",
        "threshold": "BLOCK_MEDIUM_AND_ABOVE"
        },
        {
        "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
        "threshold": "BLOCK_MEDIUM_AND_ABOVE"
        },
        {
        "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
        "threshold": "BLOCK_MEDIUM_AND_ABOVE"
        },
    ]

    # Create the model object
    model = genai.GenerativeModel(model_name="gemini-1.0-pro",
                                    generation_config=generation_config,
                                    safety_settings=safety_settings)

    # Start a chat conversation with an empty history
    convo = model.start_chat(history=[])

    # Send the user input as a message
    message = f"{user_input} convert this to user readable conversational message"
    print("in_gemini", message)
    convo.send_message(message)


    # Get and return the latest response from the conversation
    return convo.last.text